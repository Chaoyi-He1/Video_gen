# Parameters for video
video_height: 512
video_width: 512
fps: 8
max_num_frames: 56


# Parameters for dataset
data_dir: "data/train_data"


# Parameters for model
# clip model
input_dim: 768
num_frames: 56
textencoder: "openai/clip-vit-large-patch14"  # "openai/clip-vit-base-patch32", "openai/clip-vit-base-patch16", "openai/clip-vit-large-patch14", "openai/clip-vit-large-patch14-336",
textencoder_freeze: True
textencoder_projection: False

decoder_nhead: 12
decoder_dim_feedforward: 2048
decoder_dropout: 0.1
decoder_activation: "gelu"
decoder_num_layers: 12
num_querries_concats_layers: 12

# mamba model
mamba_n_layer: 8
mamba_d_state: 256

# DiT model
dit_name: "DiT-XL/4"
dit_input_size: 64  # img_size // 8
dit_in_channels: 16
dit_learn_sigma: True

num_sampling_steps: 1000

# Training parameters
mini_frames: 28
